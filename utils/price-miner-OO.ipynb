{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "from scipy import stats\n",
    "from time import sleep\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import smtplib\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceMiner:\n",
    "    \n",
    "    def __init__(self, item='', max_items='', headless=True):\n",
    "        self.item = item\n",
    "        self.max_items = max_items \n",
    "        self.__browser_init(headless)\n",
    "\n",
    "    def __setup(self):\n",
    "        \"\"\"\n",
    "        Create or reset attributes used in scraping methods\n",
    "        Parameters:\n",
    "        - No parameters\n",
    "\n",
    "        Return:\n",
    "        - No return\n",
    "        \"\"\"\n",
    "        self.__name_elements  = []\n",
    "        self.__price_elements = []\n",
    "        self.__cents_elements = []\n",
    "        self.__link_elements = []\n",
    "        self.__name_values  = []\n",
    "        self.__price_values = []\n",
    "        self.__link_values = []\n",
    "\n",
    "    def __browser_init(self, headless):\n",
    "        \"\"\"\n",
    "        This method is delegated to configure and start the browser that will serve to\n",
    "        all the other intern methods.\n",
    "\n",
    "        Parameters:\n",
    "        - headless(boolean): Defines the browser visibility. The standard value is True, \n",
    "        it means that browser will work in background. If you want to see the browser working, \n",
    "        you have to set headless=False \n",
    "\n",
    "        Return:\n",
    "        - browser(object)\n",
    "        \"\"\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "        if headless:\n",
    "            options.add_argument(\"--headless\")\n",
    "        self.browser = webdriver.Chrome(options=options)\n",
    "\n",
    "    def __do_search(self, url, input_element):\n",
    "        \"\"\" \n",
    "        This method is destinated to make a simple search, given the url and the input field\n",
    "        from any website.\n",
    "\n",
    "        Paramaters:\n",
    "        - url(string): Url link from the website \n",
    "        - input_element(string): XPATH value from the main search input field.\n",
    "\n",
    "        Return:\n",
    "        -boolean\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.browser.get(url)\n",
    "            search_input = self.browser.find_element_by_xpath(input_element)\n",
    "            search_input.send_keys(self.item)\n",
    "            search_input.send_keys(Keys.ENTER)\n",
    "            sleep(2)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def show_relevants(self, df, precision):\n",
    "        \"\"\"\n",
    "        Remove the dataframe outliers.  \n",
    "\n",
    "        Parameters:\n",
    "        - df(dataframe):\n",
    "        - precision(float): 0..1 values, lower values means stronger filtering. \n",
    "\n",
    "        Return:\n",
    "        - Filtered dataframe\n",
    "        \"\"\"\n",
    "        return df[(np.abs(stats.zscore(df['Preço R$'])) < precision)]  \n",
    "    \n",
    "    def search_all(self, sort=True):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the all avaliable websites .\n",
    "\n",
    "        -Parameters:\n",
    "        sort: boolean.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        df1 = self.shopee()\n",
    "        df2 = self.mercadolivre()\n",
    "        df3 = self.amazon()\n",
    "        df4 = self.magalu()\n",
    "        dataframes = [df1, df2, df3, df4]\n",
    "        final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "        if sort:\n",
    "            return final_dataframe.sort_values(by=['Preço R$'])\n",
    "        else:\n",
    "            return final_dataframe\n",
    "\n",
    "\n",
    "    def amazon(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Amazon website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__setup()\n",
    "        url = 'http://amazon.com.br'\n",
    "        place = \"Amazon\"\n",
    "        input_element = '//*[@id=\"twotabsearchtextbox\"]'\n",
    "        b = self.browser\n",
    "        if self.__do_search(url, input_element):\n",
    "            self.__name_elements  = b.find_elements_by_class_name('a-size-base-plus')\n",
    "            self.__price_elements = b.find_elements_by_class_name('a-price-whole')\n",
    "            self.__cents_elements = b.find_elements_by_class_name('a-price-fraction')\n",
    "            self.__link_elements  = b.find_elements_by_class_name('s-no-outline')\n",
    "            for i in range(0, max_items):\n",
    "                self.__name_values.append(self.__name_elements[i].text)\n",
    "                self.__cents_elements[i] = int(self.__cents_elements[i].text)/100\n",
    "                self.__price_values.append(float(self.__price_elements[i].text.replace('.','')) \n",
    "                                                                  + self.__cents_elements[i])\n",
    "                self.__link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "        data = {'Item':self.__name_values, 'Preço R$': self.__price_values, \n",
    "                \"Local\": place, 'Link': self.__link_values}\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def mercadolivre(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Mercado Livre website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__setup()\n",
    "        url = 'http://mercadolivre.com.br'\n",
    "        place = \"Mercado Livre\"\n",
    "        input_element = '/html/body/header/div/form/input'\n",
    "        b = self.browser\n",
    "\n",
    "        if self.__do_search(url, input_element):  \n",
    "            ml_items = b.find_elements_by_class_name('ui-search-layout__item') \n",
    "            self.__name_elements  = b.find_elements_by_class_name('ui-search-item__title')\n",
    "            self.__price_elements = b.find_elements_by_class_name('price-tag-fraction')\n",
    "            self.__price_elements = self.__price_elements[::2]\n",
    "            for i in range(0, len(ml_items)):\n",
    "                self.__link_elements.append(ml_items[i].find_element_by_class_name('ui-search-link')) \n",
    "            for i in range(0, max_items):\n",
    "                self.__name_values.append(self.__name_elements[i].text)\n",
    "                self.__link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "                self.__price_values.append(float(self.__price_elements[i].text.replace('.','')))\n",
    "            data = {'Item':self.__name_values, 'Preço R$': self.__price_values, \n",
    "                    \"Local\": place, \"Link\": self.__link_values}        \n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def magalu(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Magazine Luiza website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__setup()\n",
    "        url   = 'https://www.magazineluiza.com.br'\n",
    "        place = 'Magazine Luiza'\n",
    "        input_element = '//*[@id=\"inpHeaderSearch\"]'\n",
    "        b = self.browser\n",
    "\n",
    "        if self.__do_search(url, input_element):\n",
    "            self.__name_elements  = b.find_elements_by_class_name('productTitle')\n",
    "            self.__price_elements = b.find_elements_by_class_name('price')\n",
    "            self.__link_elements  = b.find_elements_by_class_name('product-li')\n",
    "            del self.__price_elements[0:4]  \n",
    "            for i in range(0, max_items):\n",
    "                self.__name_values.append(self.__name_elements[i].text)\n",
    "                aux_price = self.__price_elements[i].text.replace('à vista', '').replace('R$ ', '').replace(',','.')\n",
    "                if aux_price.count('.') > 1:\n",
    "                    aux_price = aux_price.replace('.','', aux_price.count('.')-1)\n",
    "                self.__price_values.append(float(aux_price))\n",
    "                self.__link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "            data = {'Item':self.__name_values, 'Preço R$': self.__price_values, \n",
    "                    \"Local\": place, 'Link': self.__link_values}\n",
    "            return pd.DataFrame(data)\n",
    "    \n",
    "    def shopee(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Shopee website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        self.__setup()\n",
    "        url = 'https://shopee.com.br'\n",
    "        place = 'Shopee'\n",
    "        input_element = '//*[@id=\"main\"]/div/div[2]/div[1]/div[2]/div/div[1]/div[1]/div/form/input'\n",
    "        b = self.browser\n",
    "        if self.__do_search(url, input_element):\n",
    "            sleep(2)\n",
    "            for i in range(1, self.max_items+1):\n",
    "                self.__name_elements.append(b.find_element_by_xpath(f'/html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[{i}]/a/div/div/div[2]/div[1]/div[1]/div'))\n",
    "                self.__price_elements.append(b.find_element_by_xpath(f'/html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[{i}]/a/div/div/div[2]/div[2]/div/span[2]'))\n",
    "                self.__link_elements.append(b.find_element_by_xpath(f'/html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[{i}]/a'))                             \n",
    "            \n",
    "            for i in range(0, max_items):\n",
    "                self.__name_values.append(self.__name_elements[i].text)                         \n",
    "                aux_price = self.__price_elements[i].text.replace('.','').replace(',','.')\n",
    "                self.__price_values.append(float(aux_price))                      \n",
    "                self.__link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "                                            \n",
    "            data = {'Item':self.__name_values, 'Preço R$': self.__price_values, \n",
    "                    \"Local\": place, 'Link': self.__link_values}\n",
    "            return pd.DataFrame(data)\n",
    "                                            \n",
    "            \"\"\"\n",
    "            names\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[1]/a/div/div/div[2]/div[1]/div[1]/div\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[6]/a/div/div/div[2]/div[1]/div[1]/div\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[7]/a/div/div/div[2]/div[1]/div[1]/div\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[6]/a/div/div/div[2]/div[1]/div[1]/div\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[16]/a/div/div/div[2]/div[1]/div[1]/div\n",
    "            \"\"\"\n",
    "                \n",
    "            \"\"\"\n",
    "            prices\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[6]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[6]/a/div/div/div[2]/div[2]/div/span[4]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[7]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[8]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[9]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[10]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[26]/a/div/div/div[2]/div[2]/div/span[2]\n",
    "            \"\"\"\n",
    "                                         \n",
    "            \"\"\"\n",
    "            links\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[11]/a\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[26]/a\n",
    "            /html/body/div[1]/div/div[3]/div/div[2]/div/div[2]/div[27]/a\n",
    "            \"\"\"\n",
    "        \n",
    "                \n",
    "                \n",
    "if __name__ == '__main__':\n",
    "           \n",
    "    item = \"Kit de Cuecas\"  # items[random.randint(0, len(items))]\n",
    "    max_items = 10\n",
    "    pesquisa_preco = PriceMiner(item, max_items, headless=False)\n",
    "   \n",
    "    #display(pesquisa_preco.shopee())\n",
    "    \n",
    "    produtos = pesquisa_preco.show_relevants(pesquisa_preco.search_all(), 1)\n",
    "    produtos.to_html(\"tabela_produtos.html\")\n",
    "    pesquisa_preco.browser.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email-enviado com sucesso\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    email_from = \"kronenautobots@gmail.com\"\n",
    "    email_to = \"mtsilva2303@gmail.com\"\n",
    "    smtp = \"smtp.gmail.com\"\n",
    "    excel_file = \"tabela_produtos.html\"\n",
    "    msg = EmailMessage()\n",
    "    msg['Subject'] = f\"Resultado de Pesquisa por: {item}\"\n",
    "    msg['From'] = email_from\n",
    "    msg['To'] = email_to\n",
    "    msg.set_content(f\"\"\"\n",
    "        Segue em anexo os resultados da pesquisa pelo produto: {item}\n",
    "        nos formatos solicitaddos.\n",
    "        \n",
    "    \"\"\")\n",
    "    \n",
    "    with open(excel_file, 'rb') as f:\n",
    "        file_data = f.read()\n",
    "        \n",
    "    msg.add_attachment(file_data, maintype=\"application\", subtype=\"html\", filename=excel_file)\n",
    "    server = smtplib.SMTP(smtp, 587)\n",
    "    server.starttls()\n",
    "    server.login(email_from, open('senha.txt').read().strip())\n",
    "    server.send_message(msg)\n",
    "    server.quit()\n",
    "    print('Email-enviado com sucesso')\n",
    "except:\n",
    "    print('Erro ao enviar e-mail')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
