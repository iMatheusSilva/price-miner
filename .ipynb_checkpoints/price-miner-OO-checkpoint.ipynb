{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "from scipy import stats\n",
    "from time import sleep\n",
    "import pandas as pd  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceMiner:\n",
    "    \n",
    "    def __init__(self, item='', max_items='', headless=True):\n",
    "        self.item = item\n",
    "        self.max_items = max_items \n",
    "        self.__browser_init(headless)\n",
    "\n",
    "    def __var_reset(self):\n",
    "        \"\"\"\n",
    "        Create or reset global variables used in scraping methods\n",
    "        Parameters:\n",
    "        - No parameters\n",
    "\n",
    "        Return:\n",
    "        - No return\n",
    "        \"\"\"\n",
    "        self.__name_elements  = []\n",
    "        self.__price_elements = []\n",
    "        self.__cents_elements = []\n",
    "        self.__link_elements = []\n",
    "        self.name_values  = []\n",
    "        self.price_values = []\n",
    "        self.link_values = []\n",
    "\n",
    "    def __browser_init(self, headless):\n",
    "        \"\"\"\n",
    "        This method is delegated to configure and start the browser that will serve to\n",
    "        all the other intern methods.\n",
    "\n",
    "        Parameters:\n",
    "        - headless(boolean): Defines the browser visibility. The standard value is True, \n",
    "        it means that browser will work in background. If you want to see the browser working, \n",
    "        you have to set headless=False \n",
    "\n",
    "        Return:\n",
    "        - browser(object)\n",
    "        \"\"\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "        if headless:\n",
    "            options.add_argument(\"--headless\")\n",
    "        self.browser = webdriver.Chrome(options=options)\n",
    "\n",
    "    def __do_search(self, url, input_element):\n",
    "        \"\"\" \n",
    "        This method is destinated to make a simple search, given the url and the input field\n",
    "        from any website.\n",
    "\n",
    "        Paramaters:\n",
    "        - url(string): Url link from the website \n",
    "        - input_element(string): XPATH value from the main search input field.\n",
    "\n",
    "        Return:\n",
    "        -boolean\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.browser.get(url)\n",
    "            search_input = self.browser.find_element_by_xpath(input_element)\n",
    "            search_input.send_keys(self.item)\n",
    "            search_input.send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def show_relevants(self, df, precision):\n",
    "        \"\"\"\n",
    "        Remove the dataframe outliers.  \n",
    "\n",
    "        Parameters:\n",
    "        - df(dataframe):\n",
    "        - precision(float): 0..1 values, lower values means stronger filtering. \n",
    "\n",
    "        Return:\n",
    "        - Filtered dataframe\n",
    "        \"\"\"\n",
    "        return df[(np.abs(stats.zscore(df['Preço R$'])) < precision)]  \n",
    "\n",
    "\n",
    "    def amazon(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Amazon website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__var_reset()\n",
    "        url = 'http://amazon.com.br'\n",
    "        place = \"Amazon\"\n",
    "        input_element = '//*[@id=\"twotabsearchtextbox\"]'\n",
    "        b = self.browser\n",
    "        if self.__do_search(url, input_element):\n",
    "            self.__name_elements  = b.find_elements_by_class_name('a-size-base-plus')\n",
    "            self.__price_elements = b.find_elements_by_class_name('a-price-whole')\n",
    "            self.__cents_elements = b.find_elements_by_class_name('a-price-fraction')\n",
    "            self.__link_elements  = b.find_elements_by_class_name('s-no-outline')\n",
    "            for i in range(0, max_items):\n",
    "                self.name_values.append(self.__name_elements[i].text)\n",
    "                self.__cents_elements[i] = int(self.__cents_elements[i].text)/100\n",
    "                self.price_values.append(float(self.__price_elements[i].text.replace('.','')) \n",
    "                                                                  + self.__cents_elements[i])\n",
    "                self.link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "        data = {'Item':self.name_values, 'Preço R$': self.price_values, \"Local\": place, 'Link': self.link_values}\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def mercadolivre(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Mercado Livre website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__var_reset()\n",
    "        url = 'http://mercadolivre.com.br'\n",
    "        place = \"Mercado Livre\"\n",
    "        input_element = '/html/body/header/div/form/input'\n",
    "        b = self.browser\n",
    "\n",
    "        if self.__do_search(url, input_element):  \n",
    "            ml_items = b.find_elements_by_class_name('ui-search-layout__item') \n",
    "            self.__name_elements  = b.find_elements_by_class_name('ui-search-item__title')\n",
    "            self.__price_elements = b.find_elements_by_class_name('price-tag-fraction')\n",
    "            self.__price_elements = self.__price_elements[::2]\n",
    "            for i in range(0, len(ml_items)):\n",
    "                self.__link_elements.append(ml_items[i].find_element_by_class_name('ui-search-link')) \n",
    "            for i in range(0, max_items):\n",
    "                self.name_values.append(self.__name_elements[i].text)\n",
    "                self.link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "                self.price_values.append(float(self.__price_elements[i].text.replace('.','')))\n",
    "            data = {'Item':self.name_values, 'Preço R$': self.price_values, \"Local\": place, \"Link\": self.link_values}        \n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def magalu(self):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the Magazine Luiza website\n",
    "\n",
    "        -Parameters:\n",
    "        No external parameters needed.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        self.__var_reset()\n",
    "        url   = 'https://www.magazineluiza.com.br'\n",
    "        place = 'Magazine Luiza'\n",
    "        input_element = '//*[@id=\"inpHeaderSearch\"]'\n",
    "        b = self.browser\n",
    "\n",
    "        if self.__do_search(url, input_element):\n",
    "            self.__name_elements  = b.find_elements_by_class_name('productTitle')\n",
    "            self.__price_elements = b.find_elements_by_class_name('price')\n",
    "            self.__link_elements  = b.find_elements_by_class_name('product-li')\n",
    "            del self.__price_elements[0:4]  \n",
    "            for i in range(0, max_items):\n",
    "                self.name_values.append(self.__name_elements[i].text)\n",
    "                aux_price = self.__price_elements[i].text.replace('à vista', '').replace('R$ ', '').replace(',','.')\n",
    "                if aux_price.count('.') > 1:\n",
    "                    aux_price = aux_price.replace('.','', aux_price.count('.')-1)\n",
    "                self.price_values.append(float(aux_price))\n",
    "                self.link_values.append(self.__link_elements[i].get_attribute('href'))\n",
    "            data = {'Item':self.name_values, 'Preço R$': self.price_values, \"Local\": place, 'Link': self.link_values}\n",
    "            return pd.DataFrame(data)\n",
    "\n",
    "    def search_all(self, sort=True):\n",
    "        \"\"\"\n",
    "        This method performs a web-scrap search on the all avaliable websites .\n",
    "\n",
    "        -Parameters:\n",
    "        sort: boolean.\n",
    "\n",
    "        -Return:\n",
    "        Dataframe\n",
    "        \"\"\"\n",
    "        df1 = self.magalu()\n",
    "        df2 = self.mercadolivre()\n",
    "        df3 = self.amazon()\n",
    "        dataframes = [df1, df2, df3]\n",
    "        final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "        if sort:\n",
    "            return final_dataframe.sort_values(by=['Preço R$'])\n",
    "        else:\n",
    "            return final_dataframe\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Preço R$</th>\n",
       "      <th>Local</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headset K-Mex Gamer ARS9 LED RGB Com Microfone...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>https://www.amazon.com.br/gp/slredirect/picass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Item  Preço R$   Local  \\\n",
       "0  Headset K-Mex Gamer ARS9 LED RGB Com Microfone...     155.0  Amazon   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.amazon.com.br/gp/slredirect/picass...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    item = 'Microfone Gamer'\n",
    "    max_items = 10        \n",
    "    x = PriceMiner(item, max_items, headless=False)\n",
    "    #magalu = x.magalu()\n",
    "    #display(magalu)\n",
    "    \n",
    "    amazon = x.amazon()\n",
    "    display(amazon)\n",
    "    \n",
    "    #display(x.search_all())\n",
    "    x.browser.close()\n",
    "    \n",
    "    #frames = [amazon,magalu]\n",
    "    #final_table = pd.concat(frames)\n",
    "    #display(final_table)\n",
    "    #mercadolivre = x.mercadolivre()\n",
    "    #display(mercadolivre)\n",
    "    #display(x.show_relevants(amazon, 1))\n",
    "    #display(x.show_relevants(mercadolivre, 1))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
